{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY8osKKXfBv1XAVJhdaqIN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armandoordonez/eda_couse/blob/main/3_5_pipeline_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14C24tVVh4Xk"
      },
      "outputs": [],
      "source": [
        "# importamos las librerias\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "# Metricas\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# importing pipes for making the Pipe flow\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pasos 1. PC, 2 estandarización, 3. decision tree\n",
        "\n",
        "pipe = Pipeline([('paso_pca', PCA(n_components = 2)), ('paso_estandarizacion', StandardScaler()),  ('paso_decision_tree', DecisionTreeClassifier())], verbose = True)\n",
        "\n",
        "# COn  fit aplicamos todo\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(accuracy_score(y_test, pipe.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihqTw6g8iPtg",
        "outputId": "5c0835ee-c2a4-4c63-836b-84f3c60538a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline] .......... (step 1 of 3) Processing paso_pca, total=   0.0s\n",
            "[Pipeline]  (step 2 of 3) Processing paso_estandarizacion, total=   0.0s\n",
            "[Pipeline]  (step 3 of 3) Processing paso_decision_tree, total=   0.0s\n",
            "0.8933333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline([('paso_decision_tree', DecisionTreeClassifier())], verbose = True)\n",
        "\n",
        "# fitting the data in the pipeline\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "print(accuracy_score(y_test, pipe.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apzqj_3DiX_5",
        "outputId": "df7ec7f8-efda-436a-e26e-618b9678e7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline]  (step 1 of 1) Processing paso_decision_tree, total=   0.0s\n",
            "0.9466666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cargamos el dataset de prueba\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "#Partimos los datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.50)\n",
        "\n",
        "# paso 1 estandarización, paso 2 clasificadro\n",
        "\n",
        "pipe = Pipeline([('paso_estandarizacion', StandardScaler()), ('paso_decision_tree', DecisionTreeClassifier())], verbose = True)\n",
        "\n",
        "# Con fit aplica todos los pasos\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# mostramos los resultados\n",
        "print(accuracy_score(y_test, pipe.predict(X_test)))"
      ],
      "metadata": {
        "id": "WGpYkKKP5VAc",
        "outputId": "cf26cbe2-a385-40b2-f8d8-a130c5f5d65c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline]  (step 1 of 2) Processing paso_estandarizacion, total=   0.0s\n",
            "[Pipeline]  (step 2 of 2) Processing paso_decision_tree, total=   0.0s\n",
            "0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Tutorial Avanzado: Uso de Custom Transformers en Python para Personalizar la Preparación de Datos\n",
        "\n",
        "# Introducción\n",
        "# En este tutorial aprenderás a crear y utilizar transformadores personalizados (Custom Transformers) en Python\n",
        "# utilizando la biblioteca `scikit-learn`. Estos transformadores permiten personalizar la preparación de datos\n",
        "# en pipelines y adaptarla a necesidades específicas.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Crear un dataset de ejemplo\n",
        "def generar_datos():\n",
        "    np.random.seed(42)\n",
        "    n = 1000\n",
        "    X = pd.DataFrame({\n",
        "        'caracteristica_1': np.random.uniform(0, 100, n),\n",
        "        'caracteristica_2': np.random.uniform(0, 50, n),\n",
        "        'caracteristica_3': np.random.normal(50, 10, n),\n",
        "    })\n",
        "    # Etiqueta con una relación no lineal para propósitos didácticos\n",
        "\n",
        "    y = (X['caracteristica_1'] + X['caracteristica_2'] + np.random.normal(0, 5, n) > 100).astype(int)\n",
        "    return X, y\n",
        "\n",
        "# Generar el dataset\n",
        "X, y = generar_datos()\n",
        "\n",
        "\n",
        "# Dividir los datos\n",
        "X_entreno, X_prueba, y_entreno, y_prueba = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# ---- CREACIÓN DE UN CUSTOM TRANSFORMER ----\n",
        "class GenerarVariablesPersonalizadas(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Un transformador personalizado para generar nuevas variables basadas en las columnas existentes.\n",
        "    \"\"\"\n",
        "    def __init__(self, crear_interacciones=True):\n",
        "        self.crear_interacciones = crear_interacciones\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        # Crear nuevas columnas\n",
        "        X['suma_caracteristicas'] = X['caracteristica_1'] + X['caracteristica_2']\n",
        "        X['diferencia_caracteristicas'] = X['caracteristica_1'] - X['caracteristica_3']\n",
        "\n",
        "        # Crear interacciones si está habilitado\n",
        "        if self.crear_interacciones:\n",
        "            X['producto_caracteristicas'] = X['caracteristica_1'] * X['caracteristica_2']\n",
        "        return X\n",
        "\n",
        "# ---- CREAR UN PIPELINE COMPLETO ----\n",
        "pipeline = Pipeline([\n",
        "    ('generador', GenerarVariablesPersonalizadas(crear_interacciones=True)),\n",
        "    ('escalador', StandardScaler()),\n",
        "    ('modelo', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Entrenar el pipeline\n",
        "pipeline.fit(X_entreno, y_entreno)\n",
        "\n",
        "# Evaluar el modelo\n",
        "y_pred = pipeline.predict(X_prueba)\n",
        "precision = accuracy_score(y_prueba, y_pred)\n",
        "\n",
        "print(f\"Precisión del modelo con custom transformer: {precision:.4f}\")\n",
        "\n",
        "# ---- COMPARAR CON UN MODELO SIN TRANSFORMADOR PERSONALIZADO ----\n",
        "modelo_basico = Pipeline([\n",
        "    ('escalador', StandardScaler()),\n",
        "    ('modelo', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Entrenar el pipeline básico\n",
        "modelo_basico.fit(X_entreno, y_entreno)\n",
        "\n",
        "# Evaluar el modelo básico\n",
        "y_pred_basico = modelo_basico.predict(X_prueba)\n",
        "precision_basico = accuracy_score(y_prueba, y_pred_basico)\n",
        "\n",
        "print(f\"Precisión del modelo sin custom transformer: {precision_basico:.4f}\")\n",
        "\n",
        "# ---- RESUMEN ----\n",
        "print(\"\\nResumen del impacto del Custom Transformer:\")\n",
        "print(f\"Precisión con custom transformer: {precision:.4f}\")\n",
        "print(f\"Precisión sin custom transformer: {precision_basico:.4f}\")\n",
        "\n",
        "# Conclusión\n",
        "# Este tutorial muestra que los Custom Transformers permiten agregar flexibilidad y potencia al preprocesamiento\n",
        "# de datos en pipelines, lo que puede mejorar el rendimiento de los modelos.\n"
      ],
      "metadata": {
        "id": "_aHFqlzmiede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47aaccd8-317e-491b-d64e-625cd961ea7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo con custom transformer: 0.9600\n",
            "Precisión del modelo sin custom transformer: 0.9567\n",
            "\n",
            "Resumen del impacto del Custom Transformer:\n",
            "Precisión con custom transformer: 0.9600\n",
            "Precisión sin custom transformer: 0.9567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xvWc910vaSTI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}